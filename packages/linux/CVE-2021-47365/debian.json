{
  "description": "In the Linux kernel, the following vulnerability has been resolved:  afs: Fix page leak  There's a loop in afs_extend_writeback() that adds extra pages to a write we want to make to improve the efficiency of the writeback by making it larger.  This loop stops, however, if we hit a page we can't write back from immediately, but it doesn't get rid of the page ref we speculatively acquired.  This was caused by the removal of the cleanup loop when the code switched from using find_get_pages_contig() to xarray scanning as the latter only gets a single page at a time, not a batch.  Fix this by putting the page on a ref on an early break from the loop. Unfortunately, we can't just add that page to the pagevec we're employing as we'll go through that and add those pages to the RPC call.  This was found by the generic/074 test.  It leaks ~4GiB of RAM each time it is run - which can be observed with \"top\".",
  "scope": "local",
  "releases": {
    "bookworm": {
      "status": "resolved",
      "repositories": {
        "bookworm": "6.1.148-1",
        "bookworm-security": "6.1.158-1"
      },
      "fixed_version": "5.14.9-1",
      "urgency": "not yet assigned"
    },
    "bullseye": {
      "status": "resolved",
      "repositories": {
        "bullseye": "5.10.223-1",
        "bullseye-security": "5.10.244-1"
      },
      "fixed_version": "0",
      "urgency": "unimportant"
    },
    "forky": {
      "status": "resolved",
      "repositories": {
        "forky": "6.16.12-2"
      },
      "fixed_version": "5.14.9-1",
      "urgency": "not yet assigned"
    },
    "sid": {
      "status": "resolved",
      "repositories": {
        "sid": "6.17.7-2"
      },
      "fixed_version": "5.14.9-1",
      "urgency": "not yet assigned"
    },
    "trixie": {
      "status": "resolved",
      "repositories": {
        "trixie": "6.12.43-1",
        "trixie-security": "6.12.48-1"
      },
      "fixed_version": "5.14.9-1",
      "urgency": "not yet assigned"
    }
  }
}