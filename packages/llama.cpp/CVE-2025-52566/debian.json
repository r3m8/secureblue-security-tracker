{
  "description": "llama.cpp is an inference of several LLM models in C/C++. Prior to version b5721, there is a signed vs. unsigned integer overflow in llama.cpp's tokenizer implementation (llama_vocab::tokenize) (src/llama-vocab.cpp:3036) resulting in unintended behavior in tokens copying size comparison. Allowing heap-overflowing llama.cpp inferencing engine with carefully manipulated text input during tokenization process. This issue has been patched in version b5721.",
  "debianbug": 1108368,
  "scope": "local",
  "releases": {
    "sid": {
      "status": "resolved",
      "repositories": {
        "sid": "6641+dfsg-1"
      },
      "fixed_version": "5760+dfsg-1",
      "urgency": "not yet assigned"
    }
  }
}